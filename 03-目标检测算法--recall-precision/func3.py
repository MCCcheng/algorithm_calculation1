# -*- coding:utf-8 -*-
"""
@author: JunCheng
@file: func3.py
@time: 2023/9/13 9:34
@desc: 
"""

import numpy as np
from pybaseutils.metrics import plot_pr, plot_roc, class_report

true_labels = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
               0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
               1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,
               1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,
               1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,
               0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
               1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]
pred_labels = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
               0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
               1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,
               1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,
               1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,
               0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,
               1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]
pred_scores = [0.039744, 0.23806, 0.106367, 0.072603, 0.142959, 0.121901, 0.096782, 0.033784, 0.16028, 0.055123,
               0.105894, 0.245011, 0.066435, 0.238938, 0.066017, 0.128727, 0.101805, 0.08934, 0.061392, 0.137288,
               0.127706, 0.109124, 0.189732, 0.038149, 0.073314, 0.108679, 0.094917, 0.057067, 0.071398, 0.20094,
               0.142219, 0.067029, 0.13857, 0.060249, 0.175484, 0.155172, 0.251, 0.14574, 0.115127, 0.144509, 0.14,
               0.293599, 0.072871, 0.056151, 0.030876, 0.180599, 0.197778, 0.070792, 0.061538, 0.207335, 0.036598,
               0.161915, 0.112382, 0.14197, 0.157562, 0.129849, 0.131545, 0.170791, 0.042187, 0.173362, 0.047182,
               0.137035, 0.165217, 0.135415, 0.12013, 0.071429, 0.211709, 0.188478, 0.038862, 0.077372, 0.066667,
               0.138854, 0.203322, 0.11442, 0.130145, 0.076455, 0.151515, 0.034483, 0.188196, 0.077129, 0.101235,
               0.101686, 0.176283, 0.21981, 0.175507, 0.177953, 0.215054, 0.368247, 0.273191, 0.153259, 0.155348,
               0.113891, 0.034508, 0.063633, 0.14433, 0.096914, 0.326628, 0.84559, 0.635101, 0.590909, 0.376126,
               0.588182, 0.645284, 0.404308, 0.544208, 0.230405, 0.325831, 0.264805, 0.105538, 0.132852, 0.059364,
               0.145202, 0.224876, 0.467018, 0.273217, 0.195625, 0.189118, 0.067983, 0.044139, 0.266279, 0.126362,
               0.14304, 0.058759, 0.386, 0.247282, 0.143258, 1.553896, 0.254286, 0.176, 0.343736, 0.273984, 0.145472,
               0.471673, 0.128954, 0.410055, 0.28315, 0.430351, 0.221785, 0.094248, 0.113468, 0.308803, 0.073777,
               0.184939, 0.313131, 0.097516, 0.111888, 0.258803, 0.175497, 0.279297, 0.091603, 0.363978, 0.192747,
               0.101852, 0.185129, 0.363278, 0.13861, 0.283688, 0.346714, 0.300693, 0.143654, 0.330532, 0.320391,
               0.148268, 0.277029, 0.346853, 0.419808, 0.185231, 0.153529, 0.12, 0.141487, 0.169001, 0.275446, 0.071351,
               0.374261, 0.132675, 0.484277, 0.227816, 0.260665, 0.237152, 0.186008, 0.271046, 0.178295, 0.267445,
               0.243916, 0.289474, 0.47799, 0.350967, 0.446105, 0.191209, 0.184883, 0.216481, 0.328012, 0.078566,
               0.150943, 0.176471, 0.079452, 0.169811, 0.042742, 0.028, 0.096559, 0.157357, 0.630736, 0.232877,
               0.101673, 0.244737, 0.368505, 0.195745, 0.006051, 0.192388, 0.109212, 0.064116, 0.013289, 0.41737,
               0.468639, 0.358439, 0.312977, 0.4, 0.427184, 0.5484, 0.780513, 0.294441, 0.140625, 0.153264, 0.203724,
               0.251113, 0.212721, 0.261428, 0.267221, 0.066281, 0.328205, 0.295659, 0.294001, 0.307152, 0.098765,
               0.355978, 0.134637, 0.161549, 0.718182, 0.552941, 0.6875, 0.365008, 0.179775, 0.371483, 0.280986,
               0.40819, 0.574583, 0.316634, 0.141226, 0.122123, 0.167846, 0.210879, 0.197126, 0.095084, 0.718444,
               0.702633, 0.165845, 0.10991, 0.08604, 0.655914, 0.352214, 0.715054, 0.311484, 0.523452, 0.242465,
               0.424869, 0.269272, 0.340718, 0.164948]

from my_utils.metrics.classification.classification_report import *

target_names = ["A0", "A1"]
confuse_file = "confuse.csv"
out_result = get_classification_report(true_labels, pred_labels, target_names=target_names, output_dict=False)
print(out_result)
get_confusion_matrix(true_labels, pred_labels,
                     target_names=target_names,
                     normalization=False,
                     filename=confuse_file,
                     plot=True,
                     title="Confusion Matrix")
